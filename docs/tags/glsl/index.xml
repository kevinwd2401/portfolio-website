<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>GLSL on Kevin Du</title>
    <link>https://kevinwd2401.github.io/portfolio-website/tags/glsl/</link>
    <description>Recent content in GLSL on Kevin Du</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <atom:link href="https://kevinwd2401.github.io/portfolio-website/tags/glsl/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Mini Minecraft</title>
      <link>https://kevinwd2401.github.io/portfolio-website/projects/mini-minecraft/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://kevinwd2401.github.io/portfolio-website/projects/mini-minecraft/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;../../images/projects/minecraft_landscape.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;My team and I built a voxel game engine inspired by Minecraft, using C++ and GLSL. This experience taught me a lot about GPU rendering pipelines. My contributions include:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Procedural biome assets&lt;/li&gt;&#xA;&lt;li&gt;Procedural biome grass coloring&lt;/li&gt;&#xA;&lt;li&gt;Water waves and specular reflection&lt;/li&gt;&#xA;&lt;li&gt;Post-process camera overlay for water and lava&lt;/li&gt;&#xA;&lt;li&gt;Distance fog&lt;/li&gt;&#xA;&lt;li&gt;Player physics&lt;/li&gt;&#xA;&lt;li&gt;Procedural cave generation&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;procedural-assets&#34;&gt;Procedural Assets&lt;/h3&gt;&#xA;&lt;p&gt;I created 3 procedural assets: normal trees, pine trees, and ice spikes. Their sizes and appearances sample their y-positions as an efficient way to obtain randomness. They are placed along the x-z-plane with poisson disk-sampling to keep them roughly evenly spaced within their chunk.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Mini-Maya</title>
      <link>https://kevinwd2401.github.io/portfolio-website/projects/mini-maya/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://kevinwd2401.github.io/portfolio-website/projects/mini-maya/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;../../images/projects/cow_mesh.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;I developed a basic mesh editor that replicates core functionality found in modern 3D modeling software. The editor is built around a half-edge data structure, which is what many widely used modeling tools are based on. Through the interface, users can load &lt;em&gt;.obj&lt;/em&gt; files and directly manipulate mesh vertices. Supported operations include Catmull–Clark subdivision, face triangulation, edge splitting, and face extrusion.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Monte Carlo Path Tracer</title>
      <link>https://kevinwd2401.github.io/portfolio-website/projects/pathtracer/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://kevinwd2401.github.io/portfolio-website/projects/pathtracer/</guid>
      <description>&lt;p&gt;This Monte Carlo path tracer is implemented in GLSL, with the majority of computation performed on the GPU. The renderer draws on concepts from &lt;em&gt;Physically Based Rendering&lt;/em&gt; and casts rays per fragment from the camera through each pixel, simulating multiple light bounces. At each bounce, direct light sampling is weighted and contributes to the overall radiance.&lt;/p&gt;&#xA;&lt;p&gt;The path tracer implements image-based environment lighting for global illumination, different types of lights and materials/BDSFs, and uses multiple importance sampling to improve convergence speed and reduce noise.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Procedural Fireball</title>
      <link>https://kevinwd2401.github.io/portfolio-website/projects/fireball/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://kevinwd2401.github.io/portfolio-website/projects/fireball/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://github.com/kevinwd2401/hw01-fireball/raw/master/fireball.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;I create a procedural fireball with a shader in GLSL. We start by rendering a base sphere mesh, which is then deformed through stretching, tapering with bias and gain functions, and then oscillated with trig functions.&lt;/p&gt;&#xA;&lt;p&gt;The chaotic appearance is caused by radial displacement, driven by FBM Perlin noise scrolling upwards. Additional trig oscillations along the X and Z axes mimic a strong flame. The fragment shader applies discrete color banding, interpolated between two color parameters by FBM noise and then layered on top of a base color gradient.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Real-Time Physically-Based Shaders</title>
      <link>https://kevinwd2401.github.io/portfolio-website/projects/pbr/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://kevinwd2401.github.io/portfolio-website/projects/pbr/</guid>
      <description>&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th style=&#34;text-align: center&#34;&gt;&lt;img src=&#34;../../images/projects/gi_example.png&#34; alt=&#34;&#34;&gt;&lt;/th&gt;&#xA;          &lt;th style=&#34;text-align: center&#34;&gt;&lt;img src=&#34;../../images/projects/gi_example2.png&#34; alt=&#34;&#34;&gt;&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;p&gt;This shading model was implemented as part of our Advanced Rendering class, based on the real-time shading model used in &lt;a href=&#34;https://cdn2.unrealengine.com/Resources/files/2013SiggraphPresentationsNotes-26915738.pdf&#34;&gt;Unreal Engine 4&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;In our fragment shader, we implement the Torrance-Sparrow microfacet model, using approximations such as the Schlick’s approximation for fresnel term and Schlick-GGX for geometric attenuation. For image-based lighting, we precompute the diffuse and glossy irradiance with different blur thresholds via mipmaps and store it in cube textures for sampling. Also implmented are normal/displacement maps and albedo maps.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
